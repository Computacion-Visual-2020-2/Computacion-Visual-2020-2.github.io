(window.webpackJsonp=window.webpackJsonp||[]).push([[8,14,15,16,17,18,22,23,27,28],{"3bXp":function(e,a,t){e.exports=t.p+"static/c8-13ea040b9e149eef25011ed72d438a62.jpeg"},"4U26":function(e,a,t){e.exports=t.p+"static/rgb11-bc19b5d9b0d9951a441df06f54d96f01.jpeg"},F9C4:function(e,a,t){e.exports=t.p+"static/rgb-6ebe9ad1fd8073e208d0d489bc6be370.jpeg"},HWEN:function(e,a,t){e.exports=t.p+"static/c5-852404d4dfd7a722cc7da8e4cb63dead.jpeg"},Lejw:function(e,a,t){e.exports=t.p+"static/c57-b731a381e7cb2c1ae4e58ccc3cfdc45c.jpeg"},UYQJ:function(e,a,t){e.exports=t.p+"static/c19-ae28702706eeac1f0d116a01cb60135c.jpeg"},p5nM:function(e,a,t){"use strict";t.r(a);var n=t("JX7q"),l=t("dI71"),o=t("q1tI"),i=t.n(o),s=t("Wbzz"),r=t("Bl7J"),c=t("F9C4"),d=t.n(c),m=t("4U26"),u=t.n(m),p=t("ypcC"),g=t.n(p),h=t("sR8/"),b=t.n(h),E=t("HWEN"),f=t.n(E),v=t("3bXp"),C=t.n(v),q=t("UYQJ"),j=t.n(q),y=t("Lejw"),z=t.n(y),A=t("zLwg"),x=t.n(A),O=function(e){return i.a.createElement("header",{id:"header"},i.a.createElement("h2",null,"Taller de análisis de imágenes por software"),i.a.createElement("div",{className:"content"},i.a.createElement("br",null),i.a.createElement("h3",null,"Propósito"),i.a.createElement("p",null,"Introducir el análisis de imágenes/video al implementar las siguientes operaciones de análisis para imágenes/video tanto por software como por hardware (empleando shaders):"),i.a.createElement("h3",null,"Tareas:"),i.a.createElement("p",null,"Implementar las siguientes operaciones de análisis para imágenes/video:"),i.a.createElement("p",null,"* Conversión a escala de grises: promedio rgb y luma. * Aplicación de algunas máscaras de convolución. * (solo para imágenes) Despliegue del histograma y segmentación a partir del mismo. * (solo para video) Medición de la eficiencia computacional para las operaciones realizadas."),i.a.createElement("p",null,"Emplear dos canvas, uno para desplegar la imagen/video original y el otro para el resultado del análisis."),i.a.createElement("h3",null,"Discusión"),i.a.createElement("h4",null,"Medición de la eficiencia computacional para las operaciones realizadas."),i.a.createElement("h4",null,"Conversión a escala de grises"),i.a.createElement("p",null,"En fotografía, computación y colorimetría, una escala de grises es aquella en la que el valor de cada píxel es una sola muestra que representa solo una cantidad de luz, es decir, solo transporta información de intensidad. Las imágenes de este tipo, también conocidas como blanco y negro o monocromáticas, están compuestas exclusivamente por tonos de gris, que varían desde el negro en la intensidad más débil hasta el blanco en el más fuerte."),i.a.createElement("p",null,"Hoy las imágenes en escala de grises (como las fotografías) destinadas a la visualización (tanto en pantalla como impresas) se almacenan comúnmente con 8 bits por píxel muestreado. Esta profundidad de píxeles permite registrar 256 intensidades diferentes (es decir, tonos de gris) y también simplifica el cálculo ya que se puede acceder a cada muestra de píxeles individualmente como un byte completo."),i.a.createElement("p",null,"La conversión de una imagen de color arbitraria a escala de grises no es única en general, existen diversas tecnicas que abordan este problema de diferentes formas, para el caso de estudio actual se usara el metodo de conversion por promedio rgb y el metodo luma."),i.a.createElement("p",null,"Promedio RGB Este metodo consiste simplemente en asignar a cada pixel el valor correspondiente al promedio de sus canales RGB. Sin embargo ya que este metodo no toma ninguna otra consideracion fuera de la intensidad de color es comun que los resultados no sean muy precisos al representar las sombras o luminosidad de la imagen original."),i.a.createElement("p",null,"Luma Este metodo se basa en el hecho de que el ojo humano es mas sensible a unas frecuencias de luz que a otras, en particular el ojo humano es mas sensible a la luz verde, un poco menos a la luz roja y un poco menos a la azul. El metodo consiste en un promedio ponderarado de los canales RGB, el peso asignado a cada canal se da de acuerdo a la sensibilidad del ojo a ese canal, es decir el peso del canal verde sera mayor que el del canal rojo y azul. Concretamente los pesos son: 0.587 para el canal verde, 0.2999 para el canal rojo y 0.114 para el canal azul."),i.a.createElement("h3",null,"Comparativa promedio vs luma"),i.a.createElement("h4",null,"Fotografía"),i.a.createElement("img",{src:d.a,alt:"Foto"}),i.a.createElement("h4",null,"Aplicando promedio RGB"),i.a.createElement("img",{src:u.a,alt:"RGB"}),i.a.createElement("h4",null,"Aplicando Luma"),i.a.createElement("img",{src:g.a,alt:"Luma"}),i.a.createElement("br",null),i.a.createElement("p",null,"Como se puede ver en las imagenes anteriores, luma capta de mejor manera el brillo de los colores, esto se puede ver en espacial en el color amarillo y en algunos tonos de verde.")),i.a.createElement("div",{className:"content"},i.a.createElement("br",null),i.a.createElement("h3",null,"Convolución"),i.a.createElement("p",null),i.a.createElement("p",null,"También es importante resaltar que realizar la convolución de una imagen es una tarea potencialmente paralelizable, puesto que el cálculo del color de un pixel no depende del resultado de algún cálculo anterior, por lo tanto sería una gran idea abordar esta tarea mediante procesamiento paralelo usando una GPU. Para ésto, se usó la librería GLSL que permite crear shaders (programas que corren directamente en la GPU del dispositivo) de una manera muy sencilla."),i.a.createElement("p",null,"Habiendo implementado este programa se notó una notable mejoría en el rendimiento de la aplicación y renderizado de las imágenes. Sin embargo el cambio fue mucho más notorio al intentar realizar el procesamiento con un video. En el analisis que empezará a continuación se usó un video a color con dimensiones $640 \\times 360$."),i.a.createElement("p",null,"El computador sobre el cual se realizó la prueba es un HP ZBOOK 15 con las siguientes especificaciones"),i.a.createElement("p",null,"SO: Ubuntu 20.04"),i.a.createElement("p",null,"Procesador: Intel Core i7-8850H (2.6 GHz - 12 núcleos)"),i.a.createElement("p",null,"GPU: NVIDIA Corporation GP107GLM [Quadro P2000 Mobile]"),i.a.createElement("p",null,"Este es el video procesado con el kernel identidad directamente con p5.js, implicando que el procesamiento se realiza sobre la CPU de la máquina:"),i.a.createElement("img",{src:"https://media.giphy.com/media/WcGVHOeuuJpPZSzGaS/giphy.gif",alt:"p5..."}),i.a.createElement("p",null,"Ahora, viendo el mismo video e implementando el mismo algoritmo pero modificado de manera tal que pueda ejecutarse como un shader sobre el video, es decir, haciendo los cálculos sobre la GPU, obtenemos lo siguiente:"),i.a.createElement("img",{src:"https://media.giphy.com/media/PFIEJC7KVdlcilM5aL/giphy.gif",alt:"shader..."}),i.a.createElement("p",null,"Es evidente en la primer grabación de la reproducción del video cómo el video de la derecha tiene un ligero retraso, quizás no es muy evidente desde una máquina potente como en la cual se está realizando esta comparación, pero seguramente en otra máquina con un procesador más modesto esta diferencia se marcaría mucho más. Por otro lado, tenemos el gran contraste del excelente rendimiento del shader, donde los videos de la izquierda y la derecha se ejecutan con sincronía total para el ojo humano."),i.a.createElement("p",null,"Por último, se realizó esta gráfica en la cual se ve la comparación del tiempo que se toma el programa en p5.js ejecutando la función draw(), la cual se encarga del renderizado del video. Se puede corroborar cómo usando GLSL (OpenGL Shading Language) el renderizado es (casi) instantáneo, mientras que haciendo la convolución directamente en p5.js toma más de 100 veces más de tiempo."),i.a.createElement("img",{src:"https://github.com/Computacion-Visual-2020-2/Computacion-Visual-2020-2.github.io/blob/0bf40b82d9d9ea96ccbc12bd3777dfa45178b888/src/sketches/convolution/results/plot.png?raw=true"}),i.a.createElement("br",null)),i.a.createElement("div",{className:"content"},i.a.createElement("br",null),i.a.createElement("h3",null,"Histograma y Segmentacion"),i.a.createElement("p",null,"Un histograma muestra de forma grafica la cantidad de pixeles que tienen un determinado valor en cualquiera de los canales RGB. El eje x corresponde a los valores de intensidad del canal (usualmente de 0-255) mientras que el eje y corresponde a la cantidad de pixeles que tienen ese valor. Para este caso de estudio se usara una imagen a blanco y negro con el fin de no tener que analizar el histograma de los 3 canales sino de unicamente uno."),i.a.createElement("p",null,"Por su parte, la segmentacion es una de la herramientas insignia de la computacion visual, gracias a la segmentacion es posible el analisis y reconocimiento de objetos. sin ir mas alla, la segmentacion ha permitido el desarollo de importantes tecnologias como los vehiculos autonomos, el reconocimiento de rostros y el reconocimiento de tejidos maliciosos en tomografias o radiografias."),i.a.createElement("p",null,"Aunque existen varios metodos para realizar segmentacion en imagenes, en este trabajo solo se hara uso del metodo de segmentacion basada en histograma. Este metodo es muy eficiente comparado con otros metodos de segmentacion ya que tipicamente solo requiere una unica pasada a traves de todos los pixeles."),i.a.createElement("p",null,"En esta tecnica se calcula primero el histograma de la imagen y los picos y valles en el histograma determinaran los cluster o clases en las que se agruparan los pixeles de la imagen, Dependiendo de lo que se quiera hacer o del numero de cluster presentes en la imagen a cada grupo se le asigara un nuevo valor rgb, el cual puede ser el promedio rgb de los pixeles del cluster o un color previamente definido, por ejemplo si la imagen se agrupa en 2 cluster entonces se puede binarisar la imagen con dos colores (blanco y negro tipicamente)."),i.a.createElement("h4",null,"Fotografía"),i.a.createElement("img",{src:x.a,alt:"Fotografía"}),i.a.createElement("h4",null,"Cluster=2"),i.a.createElement("img",{src:b.a,alt:"Cluster=2"}),i.a.createElement("h4",null,"Cluster=5"),i.a.createElement("img",{src:f.a,alt:"Cluster=5"}),i.a.createElement("h4",null,"Cluster=8"),i.a.createElement("img",{src:C.a,alt:"Cluster=8"}),i.a.createElement("h4",null,"Cluster=19"),i.a.createElement("img",{src:j.a,alt:"Cluster=19"}),i.a.createElement("h4",null,"Cluster=57"),i.a.createElement("img",{src:z.a,alt:"Cluster=57"}),i.a.createElement("br",null),i.a.createElement("p",null,"Como se observa en las imagenes anteriores, la imagen segmentada se comporta como un separador de tonalidades, entre mas bajo el numero del cluster mas el contraste entre los grupos. Por ejemplo con 2 cluster se aprecia una clara separacion entre los tonos blancos y los tonos oscuros de la imagen mientras que con numeros mas altos de cluster la imagen se asemeja mucho mas a la orginal ya que con cada grupo de cluster va adquiriendo mas tonalidades de gris.")),i.a.createElement("nav",null,i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("convolution")}},"Convolución")),i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("BlackAndWhite")}},"B/N")),i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("histogram")}},"Histograma")))))},w=t("eC7B"),L=t("JwsL"),G=function(e){function a(a){var t;return(t=e.call(this,a)||this).state={isArticleVisible:!1,timeout:!1,articleTimeout:!1,article:"",loading:"is-loading"},t.handleOpenArticle=t.handleOpenArticle.bind(Object(n.a)(t)),t.handleCloseArticle=t.handleCloseArticle.bind(Object(n.a)(t)),t.setWrapperRef=t.setWrapperRef.bind(Object(n.a)(t)),t.handleClickOutside=t.handleClickOutside.bind(Object(n.a)(t)),t}Object(l.a)(a,e);var t=a.prototype;return t.componentDidMount=function(){var e=this;this.timeoutId=setTimeout((function(){e.setState({loading:""})}),100),document.addEventListener("mousedown",this.handleClickOutside)},t.componentWillUnmount=function(){this.timeoutId&&clearTimeout(this.timeoutId),document.removeEventListener("mousedown",this.handleClickOutside)},t.setWrapperRef=function(e){this.wrapperRef=e},t.handleOpenArticle=function(e){var a=this;this.setState({isArticleVisible:!this.state.isArticleVisible,article:e}),setTimeout((function(){a.setState({timeout:!a.state.timeout})}),325),setTimeout((function(){a.setState({articleTimeout:!a.state.articleTimeout})}),350)},t.handleCloseArticle=function(){var e=this;this.setState({articleTimeout:!this.state.articleTimeout}),setTimeout((function(){e.setState({timeout:!e.state.timeout})}),325),setTimeout((function(){e.setState({isArticleVisible:!e.state.isArticleVisible,article:""})}),350)},t.handleClickOutside=function(e){this.wrapperRef&&!this.wrapperRef.contains(e.target)&&this.state.isArticleVisible&&this.handleCloseArticle()},t.render=function(){return i.a.createElement(r.a,null,i.a.createElement("div",{id:"wrapper"},i.a.createElement(O,{onOpenArticle:this.handleOpenArticle,timeout:this.state.timeout}),i.a.createElement(w.a,{isArticleVisible:this.state.isArticleVisible,timeout:this.state.timeout,articleTimeout:this.state.articleTimeout,article:this.state.article,onCloseArticle:this.handleCloseArticle,setWrapperRef:this.setWrapperRef}),i.a.createElement(s.Link,{to:"/"},"Go back to the homepage"),i.a.createElement(L.a,{timeout:this.state.timeout})))},a}(i.a.Component);a.default=G},"sR8/":function(e,a,t){e.exports=t.p+"static/c2-ec9c56c621b97cb2fd22150db1617229.jpeg"},ypcC:function(e,a,t){e.exports=t.p+"static/luma-2ccf887e38d50483c05cb85ee285f87a.jpeg"},zLwg:function(e,a,t){e.exports=t.p+"static/original-a90dd2acc5aacf27c4ba32da7ec60743.jpeg"}}]);
//# sourceMappingURL=component---src-pages-page-2-js-efe8c8b12c6c34b23f72.js.map