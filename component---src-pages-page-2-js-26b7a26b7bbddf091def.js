(window.webpackJsonp=window.webpackJsonp||[]).push([[8,17,21,22],{"4U26":function(e,a,t){e.exports=t.p+"static/rgb11-bc19b5d9b0d9951a441df06f54d96f01.jpeg"},F9C4:function(e,a,t){e.exports=t.p+"static/rgb-6ebe9ad1fd8073e208d0d489bc6be370.jpeg"},p5nM:function(e,a,t){"use strict";t.r(a);var n=t("JX7q"),l=t("dI71"),o=t("q1tI"),i=t.n(o),r=t("Wbzz"),s=t("Bl7J"),c=t("F9C4"),d=t.n(c),m=t("4U26"),u=t.n(m),p=t("ypcC"),h=t.n(p),g=function(e){return i.a.createElement("header",{id:"header"},i.a.createElement("h2",null,"Taller de análisis de imágenes por software"),i.a.createElement("div",{className:"content"},i.a.createElement("br",null),i.a.createElement("h3",null,"Propósito"),i.a.createElement("p",null,"Introducir el análisis de imágenes/video al implementar las siguientes operaciones de análisis para imágenes/video tanto por software como por hardware (empleando shaders):"),i.a.createElement("h3",null,"Tareas:"),i.a.createElement("p",null,"Implementar las siguientes operaciones de análisis para imágenes/video:"),i.a.createElement("p",null,"* Conversión a escala de grises: promedio rgb y luma. * Aplicación de algunas máscaras de convolución. * (solo para imágenes) Despliegue del histograma y segmentación a partir del mismo. * (solo para video) Medición de la eficiencia computacional para las operaciones realizadas."),i.a.createElement("p",null,"Emplear dos canvas, uno para desplegar la imagen/video original y el otro para el resultado del análisis."),i.a.createElement("h3",null,"Discusión"),i.a.createElement("h4",null,"Medición de la eficiencia computacional para las operaciones realizadas."),i.a.createElement("h4",null,"Conversión a escala de grises"),i.a.createElement("p",null,"En fotografía, computación y colorimetría, una escala de grises es aquella en la que el valor de cada píxel es una sola muestra que representa solo una cantidad de luz, es decir, solo transporta información de intensidad. Las imágenes de este tipo, también conocidas como blanco y negro o monocromáticas, están compuestas exclusivamente por tonos de gris, que varían desde el negro en la intensidad más débil hasta el blanco en el más fuerte."),i.a.createElement("p",null,"Hoy las imágenes en escala de grises (como las fotografías) destinadas a la visualización (tanto en pantalla como impresas) se almacenan comúnmente con 8 bits por píxel muestreado. Esta profundidad de píxeles permite registrar 256 intensidades diferentes (es decir, tonos de gris) y también simplifica el cálculo ya que se puede acceder a cada muestra de píxeles individualmente como un byte completo."),i.a.createElement("p",null,"La conversión de una imagen de color arbitraria a escala de grises no es única en general, existen diversas tecnicas que abordan este problema de diferentes formas, para el caso de estudio actual se usara el metodo de conversion por promedio rgb y el metodo luma."),i.a.createElement("p",null,"Promedio RGB Este metodo consiste simplemente en asignar a cada pixel el valor correspondiente al promedio de sus canales RGB. Sin embargo ya que este metodo no toma ninguna otra consideracion fuera de la intensidad de color es comun que los resultados no sean muy precisos al representar las sombras o luminosidad de la imagen original."),i.a.createElement("p",null,"Luma Este metodo se basa en el hecho de que el ojo humano es mas sensible a unas frecuencias de luz que a otras, en particular el ojo humano es mas sensible a la luz verde, un poco menos a la luz roja y un poco menos a la azul. El metodo consiste en un promedio ponderarado de los canales RGB, el peso asignado a cada canal se da de acuerdo a la sensibilidad del ojo a ese canal, es decir el peso del canal verde sera mayor que el del canal rojo y azul. Concretamente los pesos son: 0.587 para el canal verde, 0.2999 para el canal rojo y 0.114 para el canal azul."),i.a.createElement("h3",null,"Comparativa promedio vs luma"),i.a.createElement("h4",null,"Fotografía"),i.a.createElement("img",{src:d.a,alt:"Foto"}),i.a.createElement("h4",null,"Aplicando promedio RGB"),i.a.createElement("img",{src:u.a,alt:"RGB"}),i.a.createElement("h4",null,"Aplicando Luma"),i.a.createElement("img",{src:h.a,alt:"Luma"}),i.a.createElement("br",null),i.a.createElement("p",null,"Como se puede ver en las imagenes anteriores, luma capta de mejor manera el brillo de los colores, esto se puede ver en espacial en el color amarillo y en algunos tonos de verde.")),i.a.createElement("div",{className:"content"},i.a.createElement("br",null),i.a.createElement("h3",null,"Convolución"),i.a.createElement("p",null),i.a.createElement("p",null,"También es importante resaltar que realizar la convolución de una imagen es una tarea potencialmente paralelizable, puesto que el cálculo del color de un pixel no depende del resultado de algún cálculo anterior, por lo tanto sería una gran idea abordar esta tarea mediante procesamiento paralelo usando una GPU. Para ésto, se usó la librería GLSL que permite crear shaders (programas que corren directamente en la GPU del dispositivo) de una manera muy sencilla."),i.a.createElement("p",null,"Habiendo implementado este programa se notó una notable mejoría en el rendimiento de la aplicación y renderizado de las imágenes. Sin embargo el cambio fue mucho más notorio al intentar realizar el procesamiento con un video. En el analisis que empezará a continuación se usó un video a color con dimensiones $640 \\times 360$."),i.a.createElement("p",null,"El computador sobre el cual se realizó la prueba es un HP ZBOOK 15 con las siguientes especificaciones"),i.a.createElement("p",null,"SO: Ubuntu 20.04"),i.a.createElement("p",null,"Procesador: Intel Core i7-8850H (2.6 GHz - 12 núcleos)"),i.a.createElement("p",null,"GPU: NVIDIA Corporation GP107GLM [Quadro P2000 Mobile]"),i.a.createElement("p",null,"Este es el video procesado con el kernel identidad directamente con p5.js, implicando que el procesamiento se realiza sobre la CPU de la máquina:"),i.a.createElement("img",{src:"https://media.giphy.com/media/WcGVHOeuuJpPZSzGaS/giphy.gif",alt:"p5..."}),i.a.createElement("p",null,"Ahora, viendo el mismo video e implementando el mismo algoritmo pero modificado de manera tal que pueda ejecutarse como un shader sobre el video, es decir, haciendo los cálculos sobre la GPU, obtenemos lo siguiente:"),i.a.createElement("img",{src:"https://media.giphy.com/media/PFIEJC7KVdlcilM5aL/giphy.gif",alt:"shader..."}),i.a.createElement("p",null,"Es evidente en la primer grabación de la reproducción del video cómo el video de la derecha tiene un ligero retraso, quizás no es muy evidente desde una máquina potente como en la cual se está realizando esta comparación, pero seguramente en otra máquina con un procesador más modesto esta diferencia se marcaría mucho más. Por otro lado, tenemos el gran contraste del excelente rendimiento del shader, donde los videos de la izquierda y la derecha se ejecutan con sincronía total para el ojo humano."),i.a.createElement("p",null,"Por último, se realizó esta gráfica en la cual se ve la comparación del tiempo que se toma el programa en p5.js ejecutando la función draw(), la cual se encarga del renderizado del video. Se puede corroborar cómo usando GLSL (OpenGL Shading Language) el renderizado es (casi) instantáneo, mientras que haciendo la convolución directamente en p5.js toma más de 100 veces más de tiempo."),i.a.createElement("img",{src:"https://github.com/Computacion-Visual-2020-2/Computacion-Visual-2020-2.github.io/blob/0bf40b82d9d9ea96ccbc12bd3777dfa45178b888/src/sketches/convolution/results/plot.png?raw=true"}),i.a.createElement("br",null)),i.a.createElement("nav",null,i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("convolution")}},"Convolución")),i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("BlackAndWhite")}},"B/N")),i.a.createElement("li",null,i.a.createElement("button",{onClick:function(){e.onOpenArticle("histogram")}},"Histograma")))))},b=t("eC7B"),E=t("JwsL"),f=function(e){function a(a){var t;return(t=e.call(this,a)||this).state={isArticleVisible:!1,timeout:!1,articleTimeout:!1,article:"",loading:"is-loading"},t.handleOpenArticle=t.handleOpenArticle.bind(Object(n.a)(t)),t.handleCloseArticle=t.handleCloseArticle.bind(Object(n.a)(t)),t.setWrapperRef=t.setWrapperRef.bind(Object(n.a)(t)),t.handleClickOutside=t.handleClickOutside.bind(Object(n.a)(t)),t}Object(l.a)(a,e);var t=a.prototype;return t.componentDidMount=function(){var e=this;this.timeoutId=setTimeout((function(){e.setState({loading:""})}),100),document.addEventListener("mousedown",this.handleClickOutside)},t.componentWillUnmount=function(){this.timeoutId&&clearTimeout(this.timeoutId),document.removeEventListener("mousedown",this.handleClickOutside)},t.setWrapperRef=function(e){this.wrapperRef=e},t.handleOpenArticle=function(e){var a=this;this.setState({isArticleVisible:!this.state.isArticleVisible,article:e}),setTimeout((function(){a.setState({timeout:!a.state.timeout})}),325),setTimeout((function(){a.setState({articleTimeout:!a.state.articleTimeout})}),350)},t.handleCloseArticle=function(){var e=this;this.setState({articleTimeout:!this.state.articleTimeout}),setTimeout((function(){e.setState({timeout:!e.state.timeout})}),325),setTimeout((function(){e.setState({isArticleVisible:!e.state.isArticleVisible,article:""})}),350)},t.handleClickOutside=function(e){this.wrapperRef&&!this.wrapperRef.contains(e.target)&&this.state.isArticleVisible&&this.handleCloseArticle()},t.render=function(){return i.a.createElement(s.a,null,i.a.createElement("div",{id:"wrapper"},i.a.createElement(g,{onOpenArticle:this.handleOpenArticle,timeout:this.state.timeout}),i.a.createElement(b.a,{isArticleVisible:this.state.isArticleVisible,timeout:this.state.timeout,articleTimeout:this.state.articleTimeout,article:this.state.article,onCloseArticle:this.handleCloseArticle,setWrapperRef:this.setWrapperRef}),i.a.createElement(r.Link,{to:"/"},"Go back to the homepage"),i.a.createElement(E.a,{timeout:this.state.timeout})))},a}(i.a.Component);a.default=f},ypcC:function(e,a,t){e.exports=t.p+"static/luma-2ccf887e38d50483c05cb85ee285f87a.jpeg"}}]);
//# sourceMappingURL=component---src-pages-page-2-js-26b7a26b7bbddf091def.js.map